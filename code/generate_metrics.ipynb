{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Metrics\n",
    "\n",
    "This notebook generates accuracy metrics for comparing the results of NPC against our gold standard. Before running this code, you need to first generate the comparison data. \n",
    "\n",
    "Generate the file `data/neural_parscit_parsed_citations.txt` by running NPC on the citation data. \n",
    "\n",
    "1. Create an executable jar by running `mvn clean compile assembly:single` in the `neural-parscit-evaluation` Java project.\n",
    "\n",
    "2.  Run the comparison with `java -jar code/neural-parscit-evaluation/target/neural-parscit-evaluation-1.0-SNAPSHOT-jar-with-dependencies.jar`. This will generate the file `data/neural_parscit_parsed_citations.txt`.\n",
    "  \n",
    "Generate the metrics by following the steps below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import confusion_matrix and classification_report from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a confusion matrix to compare the predicted labels with the actual labels and print a classification  report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[628   0   0   0   1   5   0   0   3   5   0   3]\n",
      " [  2 104   0   0   0  16   3   0   0   0   6   0]\n",
      " [  0   1 100   0   0   0   0   3   5   0   3   0]\n",
      " [  5   0   0  37   0   0   0   0   1   0   0   0]\n",
      " [  7   4   0   0   3   0   0   0   0   0   1   0]\n",
      " [ 12   0   0   0   0 147   0   6   0   1   3   0]\n",
      " [  0   0   0   0   0   0  42   2   0   1   5   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   1   0]\n",
      " [  1   0   0   0   0   0   0   1  58   0   1   6]\n",
      " [  0   0   0   0   0   0   3   0   0  47   0   0]\n",
      " [  3  31   0   0   0  15   0  15   3   0 623   3]\n",
      " [  0   0   0   0   0   0   0   1   8   1   1  53]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      author       0.95      0.97      0.96       645\n",
      "   booktitle       0.74      0.79      0.77       131\n",
      "        date       1.00      0.89      0.94       112\n",
      "      editor       1.00      0.86      0.92        43\n",
      " institution       0.75      0.20      0.32        15\n",
      "     journal       0.80      0.87      0.83       169\n",
      "    location       0.88      0.84      0.86        50\n",
      "        note       0.00      0.00      0.00         2\n",
      "       pages       0.74      0.87      0.80        67\n",
      "   publisher       0.85      0.94      0.90        50\n",
      "       title       0.97      0.90      0.93       693\n",
      "      volume       0.82      0.83      0.82        64\n",
      "\n",
      "    accuracy                           0.90      2041\n",
      "   macro avg       0.79      0.75      0.75      2041\n",
      "weighted avg       0.92      0.90      0.91      2041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = '../results/npc_analysis.txt'\n",
    "f = open(filename, 'r')\n",
    "\n",
    "labels = ['author', \n",
    "          'booktitle', \n",
    "          'date', \n",
    "          'editor', \n",
    "          'institution', \n",
    "          'journal', \n",
    "          'location', \n",
    "          'note', \n",
    "          'pages', \n",
    "          'publisher', \n",
    "          'title', \n",
    "          'volume']\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for lines in f:\n",
    "    a = lines.strip().split()\n",
    "    if len(a) == 0:\n",
    "        continue\n",
    "    y_pred.append(a[-2])\n",
    "    y_true.append(a[-1])\n",
    "    \n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred, labels=labels))\n",
    "\n",
    "print('\\nClassification Report')\n",
    "print(classification_report(y_true, y_pred, labels=labels, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
